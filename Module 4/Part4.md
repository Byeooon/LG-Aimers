#### Seq2Seq with Attention for Natural Language Understanding and Generation

---

* recurrent neural networks

* one to one
* one to many
* many to one
* many to many

* auto regressive model

* LSTM / GRU

* Attention